{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "crypto_file = pd.read_csv(r'C:\\Users\\muham\\Downloads\\crypto currency data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the data types of all columns\n",
    "crypto_file.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first have to convert time into a datetime column as its marked as a non-numerical object and we cannot analyse\n",
    "# non-numerical objects with machine learning\n",
    "from datetime import datetime\n",
    "date_time_str = crypto_file['time']\n",
    "\n",
    "crypto_file['time'] = pd.to_datetime(pd.Series(crypto_file['time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_file.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-karaoke",
   "metadata": {},
   "source": [
    "# Before making any analysis we first check if the data is clean with no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_file.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-sheet",
   "metadata": {},
   "source": [
    "# Thus the file is clean and we can proceed now with exploratory data analysis as there are 0 missing values in all located features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see all correlations in the data frame first\n",
    "crypto_file.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_file.drop(['noticeActive'], axis=1, inplace=True)\n",
    "crypto_file.drop(['time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate normally distributed data with STD 13 and Mean 250\n",
    "series1 = crypto_file['low']\n",
    "\n",
    "#generate another series based on data 1 with some added noise\n",
    "series2 = crypto_file['open']\n",
    "\n",
    "# summarize\n",
    "print('data1: mean=%.2f stdv=%.2f' % (np.mean(series1), np.std(series1)))\n",
    "print('data2: mean=%.2f stdv=%.2f' % (np.mean(series2), np.std(series2)))\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(series1, series2, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-candy",
   "metadata": {},
   "source": [
    "# so we can see that how perfectly linear the distribution of trend is between Open and Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as mn\n",
    "mn.heatmap(crypto_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-newman",
   "metadata": {},
   "source": [
    "# We can verify here that the data is clean and there is no missing value in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use a boxplot to determine if there are outliers as we cannot see it through \n",
    "# histogram\n",
    "crypto_file[['open','high','close', 'low']].plot.box();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# we shall now see how each of the four, vaires with Signal\n",
    "# we shall now use a Scatter PLot to analyse the outliers and see the relations Signal\n",
    "with plt.style.context(\"default\"):\n",
    "    fig, axes =plt.subplots(ncols=4, sharey=True,\n",
    "                            gridspec_kw={'width_ratios':[1,1,1,1], 'wspace':0})\n",
    "    y ='Signal'\n",
    "    xs =['open','high','close', 'low']\n",
    "    for x, ax in zip(xs, axes):\n",
    "        ax.scatter(crypto_file[x],crypto_file[y])\n",
    "        ax.set_xlabel(x)\n",
    "        axes[0].set_ylabel(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-nelson",
   "metadata": {},
   "source": [
    "# So we  see a very closely linked trend that signals give to open and closing prices along with high and low "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-addition",
   "metadata": {},
   "source": [
    "#________________________________#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-petroleum",
   "metadata": {},
   "source": [
    "# Now We Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with predicting the Open using DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make predictions for Open prices\n",
    "x = crypto_file['open']\n",
    "y =  crypto_file.drop(['open'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the data into 50% training set and 50% testing set\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "tx, tex, ty, tey = train_test_split(x,y,test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert all data into 2 dimensions\n",
    "tx2d = tx.values.reshape(1,-1)\n",
    "ty2d = ty.values.reshape(1,-1)\n",
    "tey2d = tey.values.reshape(1,-1)\n",
    "tex2d = tex.values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the data in the model here\n",
    "DCT = RandomForestRegressor()\n",
    "DCT.fit(tx2d,ty2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DCT.fit(tx2d,ty2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT.predict(tex2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_of_open = DCT.predict(tex2d)\n",
    "from sklearn.metrics import accuracy_score, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from numpy import std, mean\n",
    "cv1 = KFold(n_splits=10, random_state=12,shuffle= True)\n",
    "scores = cross_val_score(DCT, x, y, scoring='accuracy', cv=cv1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try recall as a scoring \n",
    "scores1 = cross_val_score(DCT, x, y, scoring='recall', cv=cv1, n_jobs=-1)\n",
    "print('Accuracy: %.3f(%.3f)' % (mean(scores1), std(scores1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try precision as a scoring\n",
    "scores2 = cross_val_score(DCT, x, y, scoring='precision', cv=cv1, n_jobs=-1)\n",
    "print('Accuracy: %.3f(%.3f)' % (mean(scores2), std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prediction_of_open);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
